<!--
%\VignetteEngine{knitr::knitr}
%\VignetteIndexEntry{Speed comparison}
-->

# Speed comparison

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Neuroblastoma data

Consider the neuroblastoma data. There are 3418 labeled examples. If
we consider subsets, how long does it take to compute the AUM and its
directional derivatives?

```{r}
data(neuroblastomaProcessed, package="penaltyLearning")
library(data.table)
nb.err <- data.table(neuroblastomaProcessed$errors)
nb.err[, example := paste0(profile.id, ".", chromosome)]
nb.X <- neuroblastomaProcessed$feature.mat
max.log <- if(interactive())3.5 else 3
(N.pred.vec <- as.integer(10^seq(1, max.log, by=0.5)))
timing.dt.list <- list()
for(N.pred in N.pred.vec){
  N.pred.names <- rownames(nb.X)[1:N.pred]
  N.diffs.dt <- aum::aum_diffs_penalty(nb.err, N.pred.names)
  pred.dt <- data.table(example=N.pred.names, pred.log.lambda=0)
  timing.df <- microbenchmark::microbenchmark(penaltyLearning={
    roc.list <- penaltyLearning::ROChange(nb.err, pred.dt, "example")
  }, aum={
    aum.list <- aum::aum(N.diffs.dt, pred.dt$pred.log.lambda)
  }, times=10)
  timing.dt.list[[paste(N.pred)]] <- with(timing.df, data.table(
    package=expr, N.pred, seconds=time/1e9))
}
(timing.dt <- do.call(rbind, timing.dt.list))

```

Below we summarize and plot these timings.

```{r}
stats.dt <- timing.dt[, .(
  q25=quantile(seconds, 0.25),
  median=median(seconds),
  q75=quantile(seconds, 0.75)
), by=.(package, N.pred)]
library(ggplot2)
gg <- ggplot()+
  geom_line(aes(
    N.pred, median, color=package),
    data=stats.dt)+
  geom_ribbon(aes(
    N.pred, ymin=q25, ymax=q75, fill=package),
    data=stats.dt,
    alpha=0.5)+
  scale_x_log10(limits=stats.dt[, c(min(N.pred), max(N.pred)*5)])+
  scale_y_log10()
directlabels::direct.label(gg, "right.polygons")

```

From the plot above we can see that both packages have similar
asymptotic time complexity. However aum is faster by
orders of magnitude (speedups shown below).

```{r}
stats.wide <- data.table::dcast(
  stats.dt, N.pred ~ package, value.var = "median")
stats.wide[, speedup := penaltyLearning/aum][]
```

## R implementation

In this section we show a base R implementation of aum.

```{r}
diffs.df <- data.frame(
  example=c(0,1,1,2,3),
  pred=c(0,0,1,0,0),
  fp_diff=c(1,1,1,0,0),
  fn_diff=c(0,0,0,-1,-1))
pred.log.lambda <- c(0,1,-1,0)
microbenchmark::microbenchmark("C++"={
  aum::aum(diffs.df, pred.log.lambda)
}, R={
  thresh.vec <- with(diffs.df, pred-pred.log.lambda[example+1])
  s.vec <- order(thresh.vec)
  sort.diffs <- data.frame(diffs.df, thresh.vec)[s.vec,]
  for(fp.or.fn in c("fp","fn")){
    ord.fun <- if(fp.or.fn=="fp")identity else rev
    fwd.or.rev <- sort.diffs[ord.fun(1:nrow(sort.diffs)),]
    fp.or.fn.diff <- fwd.or.rev[[paste0(fp.or.fn,"_diff")]]
    last.in.run <- c(diff(fwd.or.rev$thresh.vec) != 0, TRUE)
    after.or.before <-
      ifelse(fp.or.fn=="fp",1,-1)*cumsum(fp.or.fn.diff)[last.in.run]
    distribute <- function(values)with(fwd.or.rev, structure(
      values,
      names=thresh.vec[last.in.run]
    )[paste(thresh.vec)])
    out.df <- data.frame(
      before=distribute(c(0, after.or.before[-length(after.or.before)])),
      after=distribute(after.or.before))
    sort.diffs[
      paste0(fp.or.fn,"_",ord.fun(c("before","after")))
    ] <- as.list(out.df[ord.fun(1:nrow(out.df)),])
  }
  AUM.vec <- with(sort.diffs, diff(thresh.vec)*pmin(fp_before,fn_before)[-1])
  list(
    aum=sum(AUM.vec),
    deriv_mat=sapply(c("after","before"),function(b.or.a){
      s <- if(b.or.a=="before")1 else -1
      f <- function(p.or.n,suffix=b.or.a){
        sort.diffs[[paste0("f",p.or.n,"_",suffix)]]
      }
      fp <- f("p")
      fn <- f("n")
      aggregate(
        s*(pmin(fp+s*f("p","diff"),fn+s*f("n","diff"))-pmin(fp, fn)),
        list(sort.diffs$example),
        sum)$x
    }))
}, times=10)
```

It is clear that the C++ implementation is several orders of magnitude
faster.

## Synthetic data

```{r}
library(data.table)
max.N <- 1e6
(N.pred.vec <- as.integer(10^seq(1, log10(max.N), by=0.5)))
max.y.vec <- rep(c(0,1), l=max.N)
max.diffs.dt <- aum::aum_diffs_binary(max.y.vec)
set.seed(1)
max.pred.vec <- rnorm(max.N)
timing.dt.list <- list()
for(N.pred in N.pred.vec){
  print(N.pred)
  N.diffs.dt <- max.diffs.dt[1:N.pred]
  N.pred.vec <- max.pred.vec[1:N.pred]
  timing.df <- microbenchmark::microbenchmark(dt_sort={
    N.diffs.dt[order(N.pred.vec)]
  }, R_sort_radix={
    sort(N.pred.vec, method="radix")
  }, R_sort_quick={
    sort(N.pred.vec, method="quick")
  }, aum_sort={
    aum.list <- aum:::aum_sort_interface(N.diffs.dt, N.pred.vec)
  }, times=10)
  timing.dt.list[[paste(N.pred)]] <- with(timing.df, data.table(
    package=expr, N.pred, seconds=time/1e9))
}
(timing.dt <- do.call(rbind, timing.dt.list))

```

Below we summarize and plot these timings.

```{r}
stats.dt <- timing.dt[, .(
  q25=quantile(seconds, 0.25),
  median=median(seconds),
  q75=quantile(seconds, 0.75)
), by=.(package, N.pred)]
library(ggplot2)
gg <- ggplot()+
  geom_line(aes(
    N.pred, median, color=package),
    data=stats.dt)+
  geom_ribbon(aes(
    N.pred, ymin=q25, ymax=q75, fill=package),
    data=stats.dt,
    alpha=0.5)+
  scale_x_log10(limits=stats.dt[, c(min(N.pred), max(N.pred)*5)])+
  scale_y_log10()
directlabels::direct.label(gg, "right.polygons")

```

## Comparing line search speed

```{r}

X.sc <- scale(neuroblastomaProcessed$feature.mat)
keep <- apply(is.finite(X.sc), 2, all)
X.keep <- X.sc[,keep]
weight.vec <- rep(0, ncol(X.keep))
(nb.diffs <- aum::aum_diffs_penalty(nb.err, rownames(X.keep)))

atime.list <- atime::atime(
  N=2^seq(1, 8, by=1),
  setup={
    step.grid <- 10^seq(-9, 1, l=N)
  }, 
  grid={
    pred.vec <- X.keep %*% weight.vec
    aum.list <- aum::aum(nb.diffs, pred.vec)
    pred.grad.vec <- rowMeans(aum.list$derivative_mat)
    weight.grad.vec <- t(X.keep) %*% pred.grad.vec
    data.table(step.size=step.grid, aum=sapply(step.grid, function(step){
      step.weight <- weight.vec-step*weight.grad.vec
      aum::aum(nb.diffs, X.keep %*% step.weight)$aum
    }))
  },
  exact.linear=aum::aum_line_search(
    nb.diffs,
    feature.mat=X.keep,
    weight.vec=weight.vec),
  exact.quadratic=aum::aum_line_search(
    nb.diffs,
    feature.mat=X.keep,
    weight.vec=weight.vec,
    maxIterations = nrow(nb.diffs)*(nrow(nb.diffs)-1)/2),
  result=TRUE,
  seconds.limit=0.1
)
## 4 grid points faster, 8 grid points slower.
plot(atime.list)

exact.results <- atime.list$measurements[
  expr.name!="grid", 
  result[[1]]$line_search_result[, prop.step := seq(1, .N)/.N],
  by=expr.name]
exact.best <- exact.results[, .SD[which.min(aum)], by=expr.name]
grid.dt <- atime.list$measurements[expr.name=="grid", {
  result[[1]][which.min(aum)]
}, by=N]
ggplot()+
  geom_hline(aes(
    yintercept=aum, color=expr.name),
    data=exact.best)+
  geom_point(aes(
    N, aum),
    data=grid.dt)+
  scale_x_log10()
## 2 grid points larger aum than exact, 4 grid points smaller.

exact.quad <- exact.results[
  step.size<max(grid.dt$step.size)
][expr.name=="exact.quadratic"][seq(1, .N, l=1000)]
exact.lin <- exact.results[expr.name=="exact.linear"]
some.exact <- rbind(exact.quad, exact.lin)
ggplot()+
  geom_line(aes(
    step.size, aum, color=expr.name, size=expr.name),
    data=some.exact)+
  geom_point(aes(
    step.size, aum),
    data=grid.dt)+
  scale_size_manual(
    values=c(exact.linear=1.5, exact.quadratic=0.5))

atimeX.list <- atime::atime(
  N=2^seq(1, 8, by=1),
  setup={
    some.X <- X.keep[1:N,]
    (some.diffs <- aum::aum_diffs_penalty(nb.err, rownames(some.X)))
    max.it <- N*(N-1)/2
  }, 
  exact.quadratic=aum::aum_line_search(
    some.diffs,
    feature.mat=some.X,
    weight.vec=weight.vec,
    maxIterations = max.it),
  result=TRUE,
  seconds.limit=0.1
)
plot(atimeX.list)

atimeX.list$measurements[, {
  res.dt <- result[[1]]$line_search_result
  s <- res.dt$step.size
  data.table(
    min.step=s[2],
    best.step=res.dt[which.min(aum), step.size],
    max.step=max(s))
}, by=N]

```
